Maybe keep this code here. Is has a little bit more performance.
/*
	public static void stepII(Set<Variable>[][] setV, List<Terminal> word, Grammar grammar) {
		int wordLength = word.size();
		// Look at each terminal of the word
		for ( int i = 0; i < wordLength; i++ ) {
			RightHandSideElement tempTerminal = word.get( i );
			// Get all productions that have the same leftHandSide variable. This is done for all unique variables.
			// So all production in general are taken into account.
			for ( Map.Entry<Variable, List<Production>> entry : grammar.getProductionsMap().entrySet() ) {
				Variable var = entry.getKey();
				List<Production> prods = entry.getValue();
				// Check if there is one rightHandSideElement that equals the observed terminal.
				for ( Production prod : prods ) {
					if ( prod.isElementAtRightHandSide( tempTerminal ) ) {
						setV[i][i].add( var );
					}
				}
			}
		}
	}
*/

	/*
	public static Set<Variable>[][] calculateSetV(Grammar grammar, List<Terminal> word) {
		int wordLength = word.size();
		Map<Variable, List<Production>> productions = grammar.getProductionsMap();
		@SuppressWarnings("unchecked")
		Set<Variable>[][] setV = new Set[wordLength][wordLength];
		for ( int i = 0; i < wordLength; i++ ) {
			for ( int j = 0; j < wordLength; j++ ) {
				setV[i][j] = new HashSet<>(); // this generates a set with size = 0
			}
		}
		// Check whether the terminal is on the right side of the production, then add its left variable to v_ii
		stepII( setV, word, grammar );
		// l loop of the described algorithm
		for ( int l = 0; l <= wordLength - 1; l++ ) {
			// i loop of the described algorithm
			for ( int i = 0; i < wordLength - l; i++ ) {
				// k loop of the described algorithm
				for ( int k = i; k < i + l; k++ ) {
					// tempSetX contains the newly to be added variables, regarding the "X-->YZ" rule.
					// If the substring X can be concatenated with the substring Y and substring Z, whereas Y and Z
					// must be element of its specified subsets, then add the element X to setV[i][i+l]
					Set<Variable> tempSetX = new HashSet<>();
					Set<Variable> tempSetY = setV[i][k];
					Set<Variable> tempSetZ = setV[k + 1][i + l];
					Set<VariableCompound> tempSetYZ = new HashSet<>();
					// All possible concatenations of the variables yz are constructed. And so its substrings, which
					// they are able to generate
					for ( Variable y : tempSetY ) {
						for ( Variable z : tempSetZ ) {
							@SuppressWarnings("SuspiciousNameCombination")
							VariableCompound tempVariable = new VariableCompound( y, z );
							tempSetYZ.add( tempVariable );
						}
					}
					// Looking at all productions of the grammar, it is checked if there is one rightHandSideElement
					// that equals any of the concatenated variables tempSetYZ. If yes, the LeftHandSideElement or more
					// specific the variable of the production is added to the tempSetX. All according to the "X-->YZ"
					// rule.
					for ( List<Production> tempProductions : productions.values() ) {
						for ( Production tempProduction : tempProductions ) {
							for ( VariableCompound yz : tempSetYZ ) {
								if ( tempProduction.isElementAtRightHandSide( yz ) ) {
									tempSetX.add( tempProduction.getLeftHandSideElement() );
								}
							}
						}
					}
					setV[i][i + l].addAll( tempSetX );
				}
			}
		}
		return setV;
	}
*/

/**
 * Generate N grammars (N=100000) and then evaluate these regarding the different requirements.
 * Most general approaches that use no restrictions:
 * <p>
 * FIRST Approach starting from one word to N grammars:
 * 1) Randomly generate one word.
 * 2) Randomly generate grammars derived from it. Derived means using generatePartOfGrammarPropertiesFromWord
 * which is the indirect input to generateGrammar via the settings.
 * 3) Checking restrictions and producibility.
 * 3.1) Restrictions: Check the the grammar regarding its demanded restrictions, e.g. max vars per cell and so on.
 * Restrictions are PARAMETERS which still need to be identified and optimized later on.
 * r grammars do fulfill the restrictions property.
 * Maybe even use more fine grained structure of r --> more fine grained dropout rates.
 * 3.2) Producibility: Check the grammar if it can generate the word.
 * p grammars do fulfill the producibility property.
 * This will be checked with the CYK-algorithm.
 * 4) n valid grammars are the final result. n is element of [0, N] and n = r * p.
 * Usage of different success rates:
 * ////// more fine grained SR's?
 * - Success rate SR = n/N;
 * - Success rate of checking for the restrictions SRR = r/N;
 * - Success rate of checking for the producibility SRP = p/N;
 * ////// missing SRC
 * - Conditional probability for one grammar of being a validGrammar and being able to generate the word. COND = SRR*SRR.
 * <p>
 * SECOND Approach starting from one grammar to one word:
 * 1.1) Randomly generate one grammar.
 * 1.2) ResultCalculator for more restrictions regarding the grammar, e.g. maxVarCount and so on.
 * [ 1.3) Accept the grammar if all the restrictions are met, otherwise goto 1.1). In this approach it may be possible to
 * use even more restrictions, e.g. more this approach regarding specific restrictions ]
 * 3) Randomly generate words derived from it. Derived means using generatePartOfGrammarPropertiesFromGrammar
 * which is the indirect input to generateWord via the settings. One would maybe define properties for the word.
 * 4) Check for the words that can be be generated out of the grammar.
 * 5) One or more valid grammars are the final result.
 * <p>
 * <p>
 * THIRD Approach starting with the half of a word and half of grammar.
 * <p>
 * Input for word generation:
 * [GrammarProperties object] Parameters could be:
 * variables count, terminals count, sizeOfWord,
 * <p>
 * Understand why the grammar are broken, try to repair with hand.
 * How to improve a Grammar? Maybe deleting a right side.
 * <p>
 * [numberOfVars from 2 to 5, sizeOfAlphabet from 2 to 4, maxNumberOfVarsPerCell = 3]
 */